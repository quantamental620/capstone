Model Card: FX Exchange Rate Prediction using Machine Learning Models

This model aims to forecast whether the t+1 move in a currency is likely to up or down. 
The model aims to combine trading signals from four trading strategies: 
1) Short-term moving average cross-over strategy
2) Long-term moving average cross-over strategy
3) A trading strategy based on Relative Strength Indicator (RSI)
4) A trading stragey based on an estimate of fair-value using the first three prinipal components of the currencies considered

In addition to the signals from these four trading strategies, the following variables are included to be tested:
	- Historic performance of the trading strategies: The historic performance of trading strategies can sometime help weight the signals of those strategies. These variables are included to test if machine learning models can extract value for forecasting FX moves. 
	- 3m historic volatility of the currency pairs. The performance of assets can differ across diferent volatility regimes. This variable is included to try to capture this effect. 

Machine Learning models are used to predict the next day's currency moved based on these variables. Four approaches are considered:
1) Random Forest with GridSearchCV object for hypterparameter optimisation
2) XGBoost with GridSearchCV object for hypterparameter optimisation
3) Neural network with GridSearchCV object for hypterparameter optimisation
4) Random Forest with random selection of hyperparameters within user defined ranges

For models 1-3, hyperparameter optimisation is conducted individually for each currency's model. 
For model 4, the aim is to find the hyperparameters that provide a generalised specificaion across all currencies. The aim of this is to try to reduce overfitting within the training sample, given that the data set is relatively small. 

**Inputs**
- Data sourced from Yahoo Finance API with fill-forward handling for missing values.
- The value of 10 currencies (focus on Asian currencies plus EURUSD), captured at the end of the trading day in New York. The data is daily starting on 1 Jan 2004. 
- From this data, calculations are made to provide the signals of four trading strategies considered, the performance of these strategies and the historic volaility measure. 

**Output** 

Prior to the machine learning calibration, the code provdes:
- Trading signals of the four strategy considered
- Historic rolling sharpe ratio of the performance of the strategy for the 10 currencies. The sharpe ratios are caluclated on a rolling, 20-day, 60-day, 125-day and 250-day rolling window. 
- 63-day rolling historic volatility for the 10 currencies. 

For each machine learning model, the following outputs are provded:
- The accuracy statistics for each currency for the best model specification over the train, test and validation datasets. This is provided seperately for the Random Forest, XGBoost and Neural Network models.
- Similar for the Sharpe Ratio statistics, which replicated the payoff from trading the t+1 signal.
- For the Random Forest with manual parameter selection, the accuracy and Sharpe Ratio statistics are provided for the 100 models that are sampled. 

**Model Architecture** 

This is a time-series challenge. The model architecture is:

1. Create data series, using Capsonproject_datacreation:
	- Download, clean and tranform data
	- Generate short-term and long-term moving average trading signals
	- Generate RSI trading signals
	- Generate PCA fair value trading signals
2. Estimate machine learning models:
	- Prior to running models there are the following user choices:
		- Which currencies to include 
		- Which variables to include 
		- Whether a higher degree of regularisation is to be applied to the hyperparameter selection
	- Each machine learning model is contained within a cell of the Juypter notebook. Within these cells the code:
		- Contains the hyperparmeters to be used in the model calibraiton
		- Divides the data in to the training (60%), validation (20%) and test (20%) dataset. These sub-date set splits are cronological in time to preserve the inter-dependences between the data points. 
		- Estimates the model on the training data set, then creates predictions and model evaluations on the train, test and validation datasets.
		- The evaluation statisstics provided are: 1) accuracy score, 2) Sharpe ratio of a trading strategy that uses the t+1 prediction	
	- The final cells provide graphical representation of the accuarcy score and sharpe ratio across the training, test and validation data sets. 

**Performance**

Performance is measured in two ways:
- Accuracy score from correctly predicting if an exchange rate increases or declines.
- A Sharpe ratio of a trading strategy from forecasting the t+1 move in the currency. This is an assessment of whether the signal is accurate enough to provide a profitable trading strategy. 

It must be considered that forecasting currency moves is deemed a very difficult challenge. This can be see in the validation and test data sets having accuracy scores of just above 0.50 in many cases (i.e. slightly better than a coin flip). 

The performance differs across the currencies, but for simplicity, here is a summary of the average performance of the test data across the models. See charts in the Jupter notebook for more detailed statistics by currency. 
1) Random Forest with GridSearchCV: Accuracy Score: .05182; Sharpe ratio: 0.67
2) XGBoost with GridSearchCV: Accuracy Score: .5163; Sharpe ratio: 0.49
3) Neural network with GridSearchCV: Accuracy Score: .5069; Sharpe ratio:0.37
4) Random Forest with random selection: Accuracy Score: .5115; Sharpe ratio: 0.31

These performance statistics are not quite high enough to put a trading strategy into production, except for the Random forest model (A Sharpe ratio above ~0.7 is required, based on industry experience). The code has therefore been submitted to allow practioners to run alternative specifications by:
1. Changing the extrent of regularisation - very important given the tendency of in-sample fitting
2. Chaining the variables considered in the model
3. Chaning or adding more currencies. 

## Limitations

Data Limitations:
	- Ideally more history to calibrate and test the models. More history provides more market regimes for the model to be estimated over to provide a more generalised specification. 
	- The model will be sentitive to new market regimes occuring which have not been present in the training same. 
	- This model does not take into consideration fundamentals of valiables that can impact currencies. This should be consider to be added in any extention to this work. 

Model limitations:
	- Regularlisation is required to avoid in-sample overfitting. More time should be spent testing regularisation methords. 
	- The model include only information contained within past patturns of the price. Additional variables should be considered. 
	- The model should be regularly updated in order to capture the latest relationships and market regimes. 

Trade-offs: 
	- The machine learning methods tested here have limited interpretability of the variables. 

